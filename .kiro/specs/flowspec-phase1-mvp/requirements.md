# FlowSpec Phase 1 MVP 需求文档

## 项目介绍

FlowSpec Phase 1 旨在交付一个最小可行产品（MVP），展示 FlowSpec 生态系统的核心价值主张。该 MVP 将是一个名为 `flowspec-cli` 的命令行工具，能够从源代码中解析 ServiceSpec 注解，摄取 OpenTelemetry 轨迹数据，并执行规约与实际执行轨迹之间的对齐验证。

本项目遵循"吃自己的狗粮"原则，开发过程本身也由 FlowSpec 规约管理，确保我们的方法论与实现之间的一致性。

## 需求规约

### 需求 1: 核心 CLI 工具开发

**用户故事：** 作为使用微服务的开发者，我希望有一个命令行工具能够根据预定义的规约验证我的服务交互，以便在开发周期早期发现集成问题。

#### 验收标准

1. 当我运行 `flowspec-cli align --path=./my-project --trace=./traces/run-1.json --output=human` 时，系统应当执行完整的对齐验证流程
2. 当我提供无效的命令行参数时，系统应当显示有用的错误信息和使用说明
3. 当我运行 `flowspec-cli --help` 时，系统应当显示全面的帮助文档
4. 当对齐过程成功完成时，系统应当返回退出码 0
5. 当对齐过程检测到验证失败时，系统应当返回非零退出码

### 需求 2: ServiceSpec 解析器模块

**用户故事：** 作为开发者，我希望工具能够自动发现并解析源代码中的 ServiceSpec 注解，这样我就不需要手动维护单独的规约文件。

#### 验收标准

1. 当我提供源代码目录路径时，系统应当递归扫描所有支持的源文件（.java, .ts, .go）
2. 当系统遇到 `@ServiceSpec` 注解时，应当将其解析为结构化的 JSON 对象
3. 当解析前置条件和后置条件时，系统应当使用 JSONLogic 格式将其转换为结构化断言对象
4. 当源文件包含格式错误的 ServiceSpec 注解时，系统应当报告具体的解析错误和文件位置
5. 当未找到 ServiceSpec 注解时，系统应当清楚地报告这种情况

### 需求 3: OpenTelemetry 轨迹摄取器

**用户故事：** 作为开发者，我希望工具能够读取和处理 OpenTelemetry 轨迹文件，以便我能够根据规约验证实际的服务执行情况。

#### 验收标准

1. 当我提供有效的 OpenTelemetry JSON 轨迹文件时，系统应当成功解析它
2. 当轨迹文件包含多个轨迹时，系统应当按 traceId 组织 spans 以便高效查询
3. 当轨迹文件格式错误或 JSON 无效时，系统应当报告具体的解析错误
4. 当轨迹文件不存在时，系统应当报告清楚的文件未找到错误
5. 当处理轨迹时，系统应当保留所有 span 属性、时间信息和关系

### 需求 4: 对齐引擎

**用户故事：** 作为开发者，我希望工具能够将我的 ServiceSpec 断言与实际轨迹数据进行比较，以便识别预期和实际服务行为之间的差异。

#### 验收标准

1. 当比较规约与轨迹时，系统应当将 ServiceSpec operationIds 与对应的 spans 匹配
2. 当评估前置条件时，系统应当能够访问 span 属性和 startTime
3. 当评估后置条件时，系统应当能够访问 span 属性、endTime、status 和 events
4. 当 ServiceSpec 断言失败时，系统应当提供详细的失败信息，包括期望值与实际值的对比
5. 当 ServiceSpec 没有对应的轨迹数据时，系统应当报告为 SKIPPED 状态
6. 当所有断言通过时，系统应当报告 SUCCESS 状态
7. 当任何断言失败时，系统应当报告 FAILED 状态并提供具体详情

### 需求 5: 报告生成和输出

**用户故事：** 作为开发者，我希望从验证过程中获得清晰、可操作的报告，以便快速理解和修复任何问题。

#### 验收标准

1. 当生成报告时，系统应当包含汇总统计信息（总数、成功、失败、跳过的计数）
2. 当输出格式为 "human" 时，系统应当在终端显示格式化的可读报告
3. 当输出格式为 "json" 时，系统应当输出结构化的 JSON 数据
4. 当验证失败发生时，系统应当提供关于哪些断言失败以及失败原因的具体详情
5. 当显示结果时，系统应当清楚地指示每个 ServiceSpec 验证的状态

### 需求 6: 开源就绪性

**用户故事：** 作为开源贡献者，我希望项目遵循标准的开源实践，以便我能够轻松理解、贡献和使用该项目。

#### 验收标准

1. 当项目发布时，应当包含 Apache-2.0 LICENSE 文件
2. 当用户访问仓库时，应当找到包含安装和使用说明（包括 `go install` 命令）的全面 README.md
3. 当贡献者想要参与时，应当找到包含开发指南的 CONTRIBUTING.md
4. 当代码推送到主分支时，应当通过所有 CI/CD 检查（构建、代码检查、测试）
5. 当 MVP 发布时，应当提供带有清晰构建说明的源代码分发（主要平台的预构建二进制文件将在后续的次要版本中提供）

### 需求 7: 质量保证

**用户故事：** 作为维护者，我希望有全面的测试和质量控制，以确保工具的可靠性和可维护性。

#### 验收标准

1. 当测量测试覆盖率时，核心模块应当达到 >= 80% 的覆盖率
2. 当运行测试套件时，应当包含所有核心模块的单元测试
3. 当验证端到端功能时，系统应当通过至少 3 个集成测试场景
4. 当集成测试运行时，应当覆盖成功、前置条件失败和后置条件失败的情况
5. 当代码提交时，应当通过代码检查和格式化检查

### 需求 8: ServiceSpec DSL v1.0 实现

**用户故事：** 作为编写 ServiceSpecs 的开发者，我希望有一个定义良好、一致的语法来表达服务契约，以便我的规约清晰且机器可读。

#### 验收标准

1. 当编写 ServiceSpec 注解时，其断言部分（preconditions/postconditions）应当遵循有效的 JSON/YAML 格式，并能被 JSONLogic 引擎解析
2. 当使用断言表达式时，系统应当支持前置条件和后置条件的 JSONLogic 语法
3. 当评估表达式时，系统应当提供适当的上下文变量（span 属性、时间、状态）
4. 当表达式包含语法错误时，系统应当报告清晰、可操作的错误信息
5. 当表达式引用未定义变量时，系统应当报告具体的变量解析错误

### 需求 9: 多语言源代码支持

**用户故事：** 作为在多语言环境中工作的开发者，我希望 ServiceSpec 解析能够跨不同编程语言工作，以便无论实现语言如何，我都能使用一致的规约。

#### 验收标准

1. 当扫描 Java 源文件时，系统应当正确解析 `@ServiceSpec` 注解
2. 当扫描 TypeScript 源文件时，系统应当正确解析 `@ServiceSpec` 注释
3. 当扫描 Go 源文件时，系统应当正确解析 `@ServiceSpec` 注释
4. 当遇到不支持的文件类型时，系统应当优雅地跳过它们
5. 当特定文件解析失败时，系统应当继续处理其他文件并报告错误

### 需求 10: 性能和可扩展性

**用户故事：** 作为在大型代码库上工作的开发者，我希望工具能够高效地处理我的规约和轨迹，以便验证不会成为我开发工作流程的瓶颈。

#### 验收标准

1. 当处理包含 1,000 个源文件和 200 个 ServiceSpecs 的仓库时，解析过程应当在标准 CI 代理上 30 秒内完成
2. 当摄取 100MB 的 OpenTelemetry JSON 轨迹文件时，CLI 进程的峰值内存使用量不应超过 500MB
3. 当运行对齐验证时，系统应当为超过 5 秒的操作提供进度反馈
4. 当由于资源限制导致处理失败时，系统应当提供包含具体资源限制的清晰错误信息
5. 当处理并发操作时，系统应当在适用的地方保证线程安全